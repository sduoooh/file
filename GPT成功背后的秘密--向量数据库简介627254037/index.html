<div class="CollectionItem"><div></div><h1>GPT成功背后的秘密--向量数据库简介</h1><div class="RichText ztext Post-RichText css-1g0fqss" options="[object Object]"><p data-first-child=""></p><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/0.jpg';this.onerror=null;" src="./img/0.jpg" aspect-ratio ="3.2"><a class="LinkCard new" data-draft-node="block" data-draft-type="link-card" data-image="https://pic1.zhimg.com/v2-dfc0b5aa59c0ed860c55c62386e639d8_180x120.jpg" data-image-height="436" data-image-width="1024" data-text="智写AI一键写剧本" href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/QoOT8XugtgF916q2utNA0w" target="_blank"><span class="LinkCard-contents"><span class="LinkCard-title loading" data-text="true"></span><span class="LinkCard-desc loading"></span></span><span class="LinkCard-image LinkCard-image--default"></span></a><h2><b>介绍</b></h2><p data-pid="vPCQt4aD">互联网上复杂的非结构化数据正在以惊人的速度增长，比如文档、图像、视频和普通文本等形式。许多公司、组织将受益于存储和分析复杂数据，但传统数据库针对结构化数据建立，处理非结构化数据可能会很困难。如果仅通过关键词分析、数据分类可能不足以完全表示挖掘和学习到这些数据所蕴含的知识。</p><p data-pid="B4Rg63wz">幸运的是，机器学习里面有一种技术叫做：向量嵌入(vector embeddings)。向量嵌入将复杂数据对象转换为在数百或数千个不同维度的数值。(简单理解为大矩阵)。目前有许多技术用于构建向量嵌入，存在一些<b>模型[1]</b>，它们具有高性能并且易于使用。</p><p data-pid="ihhbZ3V1">向量数据库需要专门设计处理向量嵌入的独特结构，通过比较值并找到彼此最相似的向量来索引向量，以便进行易于搜索和检索。实现的技术难度比较高，到目前为止，矢量数据库只有少数拥有大量开发和管理资源的技术巨头才能使用。</p><h2><b>什么是向量嵌入(vector embeedings)</b></h2><p data-pid="YePUTFc4">向量嵌入（vector embedding）是一种将非数值的词语或符号编码成数值向量的技术。它是自然语言处理（NLP）和深度学习中常用的预处理技术。</p><p data-pid="aS1Dnitq">通常，向量嵌入是通过一个神经网络来学习的，该网络接收文本中的词语作为输入，并输出一个对应的词向量，其中词向量是一个数值向量，每个数值代表词语的某个特征。</p><p data-pid="SrrxlyNS">例如，通过向量嵌入，我们可以将词语"dog"和"cat"表示为两个不同的数值向量，并可以通过计算两个向量的距离来判断它们的相似度。 </p><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/1.jpg';this.onerror=null;" src="./img/1.jpg" aspect-ratio ="1.5928270042194093"><p class="ztext-empty-paragraph"><br/></p><p data-pid="ubwtPVU0">如果发现通过向量映射还不好理解的话，把词向量在高维空间的嵌入投影，可视化出来就能很轻松得搞明白。词义相近的词组，会在高维空间上”距离“更近。（非常重要的理论基础） </p><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/2.jpg';this.onerror=null;" src="./img/2.jpg" aspect-ratio ="1.0437636761487965"><p class="ztext-empty-paragraph"><br/></p><h2><b>什么是向量数据库</b></h2><p data-pid="Ptphq3La"><b>向量数据库是一种将数据存储为高维向量的数据库，高维向量是特征或属性的数学表示。每个向量都有一定数量的维度，范围从几十到几千不等，具体取决于数据的复杂性和粒度。向量数据库同时具有CRUD操作、元数据过滤和水平扩展等功能。</b></p><p data-pid="SweMtMed">向量通常是通过对原始数据（例如文本、图像、音频、视频等）应用某种变换或嵌入函数来生成的。嵌入函数可以基于各种方法，例如机器学习模型、词嵌入、特征提取算法。</p><p data-pid="Gg3I-ADx">向量数据库的主要优点是它允许根据向量距离或相似性对数据进行快速准确的相似性搜索和检索。这意味着您可以使用向量数据库根据语义或上下文含义查找最相似或相关的数据，而不是使用基于精确匹配或预定义标准查询数据库的传统方法。</p><p data-pid="JaD_1vhI">它们将向量嵌入组织在一起，使我们能够比较任何向量与搜索查询的向量或其他向量之间的相似度。它们也可以执行CRUD操作和元数据过滤。将传统数据库功能与搜索和比较向量的能力相结合，使得向量数据库成为强大的工具。它们在相似度搜索方面表现出色，或称为“<b>向量搜索[2]</b>”。 </p><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/3.jpg';this.onerror=null;" src="./img/3.jpg" aspect-ratio ="1.908141962421712"><p class="ztext-empty-paragraph"><br/></p><p data-pid="7Tp_PD_6">通过向量搜索，用户可以描述他们想要找到什么，而不必知道存储对象所归属的关键字或元数据分类。同时，向量搜索还可以返回类似或近邻匹配的结果，提供了更全面的结果列表，否则这些结果可能会被隐藏起来。</p><h2><b>向量数据库能干什么？</b></h2><p data-pid="3NW0U3xU">让我们来看一些向量搜索的常见用例：</p><h3><b>1. 语义搜索</b></h3><p data-pid="P97Czolc">文本搜索通常有两种方式：词法搜索和语义搜索。词法搜索是基于模式寻找精确单词或字符串匹配，就是平时我们常说的关键字匹配。语义搜索则将搜索查询或问题的含义放入上下文中，以理解文本的含义和上下文，并获得更准确和相关的搜索结果。 向量数据库，存储和索引自然语言处理模型中的向量嵌入，以更好地理解文本字符串、句子和整个文档。使用语义搜索可以让用户更快地找到所需内容，无需了解数据分类。这不仅提供了更好的用户体验，还能提高效率。</p><h3><b>2. 对图像、音频、视频等非结构化数据进行相似度搜索</b></h3><p data-pid="fd5YUmV2">传统数据库难以分类和存储非结构化数据集，如图像、音频、视频等。对每个对象手动应用关键字、描述和元数据也很繁琐。不同人对复杂数据对象的分类可能有所不同，使得搜索变得随意。向量数据库能够更好理解数据，对数据进行相似度搜索。</p><h2><b>3.搜索、推荐排序</b></h2><p data-pid="Siv4yckK">做过搜索或者推荐排序的同学，应该对<b>FAISS[3]</b> 这个库都不陌生，它是一个出色向量相似搜索类库。 向量数据库是一个类似的优秀的解决方案，可用于驱动排名和推荐引擎。向量数据库具备寻找相似物品的能力，因此它成为提供相关建议和轻松排名物品的理想选择。相似度分数也可用于对物品进行排序。 因此电商领域，可以用它为用户提供与过去购买或当前正在研究的物品相似的建议。流媒体服务(音乐、短视频）可以根据用户的歌曲评级创建个性化推荐。</p><h2><b>4. 异常检测</b></h2><p data-pid="-MSUPQbZ">既然向量数据库能够很好帮人们找到相似对象，做过异常检测（风控）的小伙伴们肯定也了解，其实聚类算法做得好，那么离群检测肯定也能做好。因为原理是一体两面的，能很快很好的找到相似的实体对象，那么找到不同的对象也是轻而易举。向量数据库在这些方向的应用是非常有效的。</p><h2><b>向量数据库实例</b></h2><p data-pid="A2dbJspk">推荐一些向量数据库，其中包括Pinecone ,ChatGPT,AutoGPT都基于它。还有一些开源方案可以关注。</p><ol><li data-pid="CCdAQ18w"><b>Pinecone[4]</b>：Pinecone 是一个向量数据库，用于索引和存储向量嵌入以进行快速检索和相似性搜索。它具有 CRUD 操作、元数据过滤和横向扩展等功能。</li></ol><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/4.jpg';this.onerror=null;" src="./img/4.jpg" aspect-ratio ="2.188679245283019"><p class="ztext-empty-paragraph"><br/></p><ol><li data-pid="39teStMv"><b>Weaviate[5]</b>：Weaviate 是一个开源的向量数据库，允许您在原始向量或数据对象上执行闪电般快速的纯向量相似性搜索，甚至带有过滤器。它还允许您将基于关键字的搜索与向量搜索技术相结合，以获得最先进的结果。</li></ol><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/5.jpg';this.onerror=null;" src="./img/5.jpg" aspect-ratio ="2.801242236024845"><p class="ztext-empty-paragraph"><br/></p><ol><li data-pid="dQUevK-9">Chroma：Chroma 是一个向量数据库，为存储和搜索高维向量提供简单的 API。它专为基于特征和属性检索数据的相似性搜索而设计。</li></ol><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/6.jpg';this.onerror=null;" src="./img/6.jpg" aspect-ratio ="1.3146944083224967"><p class="ztext-empty-paragraph"><br/></p><ol><li data-pid="Hhcjm5D-"><b>Kinetica[6]</b>：Kinetica 是一个 GPU 加速的数据库，可以存储和查询高维向量。它使用内存计算和分布式处理的组合来提供快速的查询性能。</li></ol><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/7.jpg';this.onerror=null;" src="./img/7.jpg" aspect-ratio ="1.7422535211267605"><p class="ztext-empty-paragraph"><br/></p><h2><b>为什么需要向量数据库：</b></h2><p data-pid="eQjuLv2K">答案很简单：<b>性能</b>。</p><p data-pid="matuK1We">向量数据库针对大量向量数据的存储和执行操作进行了优化，每次查询通常处理数亿个向量，并且比传统数据库的处理速度快得多。以下主要介绍向量数据库最核心的几种技术和能力：</p><ul><li data-pid="dEeo3Sc-">执行复杂的数学运算，使用“余弦相似度”等聚类技术过滤和定位“附近”的向量</li><li data-pid="OWU0cZK4">提供专门的 Vector 索引，使数据检索速度显着加快并更精确</li><li data-pid="tzLx6r2s">以更紧凑的方式存储向量，例如通过压缩和量化向量数据，尽可能多地在内存中查询数据</li><li data-pid="5Z4TgoX7">跨多台机器数据分片</li></ul><p data-pid="e_dNGesw">接下来我们深入了解一下相似性搜索相关技术：</p><h3><b>相似性搜索向量索引</b></h3><p data-pid="yncVJRAA">衡量向量之间的相关性和相似性，最常用的指标包括<b>欧几里得距离[7]</b>、<b>余弦相似度[8]</b>或<b>点积[9]</b>。传统数据库的最近邻搜索需要比较每个已索引向量，效率比较低。</p><p data-pid="JIJ6Drcm">向量数据库使用“最近邻”索引来评估相似对象之间或搜索查询之间的接近程度。传统的最近邻搜索需要比较每个已索引向量，效率比较低。</p><p data-pid="QIx81QKZ">向量数据库使用 近似最近邻（ANN）搜索技术，来评估相似对象之间或搜索查询之间的接近程度。 常用的技术包括<b><a class="wrap external" href="https://link.zhihu.com/?target=https%3A//docs.vespa.ai/en/approximate-nn-hnsw.html" rel="nofollow noreferrer" target="_blank">HNSW</a></b>、<b>inverted file index(IVF)[10]</b>和 <b>Product Quantization(PQ)[11]</b>等算法。</p><p data-pid="h84Ssjl0"><b>HHSW：</b> </p><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/8.jpg';this.onerror=null;" src="./img/8.jpg" aspect-ratio ="1.7777777777777777"><p class="ztext-empty-paragraph"><br/></p><p data-pid="S45CwDxX"><b>IVF:</b> </p><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/9.jpg';this.onerror=null;" src="./img/9.jpg" aspect-ratio ="1.6018306636155606"><p data-pid="GEBa2ZK7"><b>PQ：</b> </p><img loading="lazy" onerror="this.src='https://collection.sduoooh.me/GPT成功背后的秘密--向量数据库简介627254037/img/10.jpg';this.onerror=null;" src="./img/10.jpg" aspect-ratio ="1.6732186732186731"><a class="LinkCard new" data-draft-node="block" data-draft-type="link-card" data-image="https://pic1.zhimg.com/v2-dfc0b5aa59c0ed860c55c62386e639d8_180x120.jpg" data-image-height="436" data-image-width="1024" data-text="智写AI一键写剧本" href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/QoOT8XugtgF916q2utNA0w" target="_blank"><span class="LinkCard-contents"><span class="LinkCard-title loading" data-text="true"></span><span class="LinkCard-desc loading"></span></span><span class="LinkCard-image LinkCard-image--default"></span></a><h2><b>总结</b></h2><p data-pid="ATTtK0uv">向量数据库是AI时代的核心组件，也是方兴未艾的领域，值得深入研究和发展。ChatGPT、AutoGPT类AI助手的崛起将会带来类似于MongoDB、Redis级别的数据库创业机会。</p><p data-pid="z3Z19Drv"> #GPT #vectorDB #vector #AutoGPT</p><h3><b>参考资料</b></h3><p data-pid="dKMgd4jX">[1] </p><p data-pid="OLdMNBDk">模型: <i><a class="external" href="https://link.zhihu.com/?target=https%3A//www.sbert.net/" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://www.</span><span class="visible">sbert.net/</span><span class="invisible"></span></a></i></p><p data-pid="TLtwG5LH">[2] </p><p data-pid="V16p47U_">向量搜索: <i><a class="external" href="https://link.zhihu.com/?target=https%3A//www.algolia.com/blog/ai/what-is-vector-search/%23%3A~%3Atext%3DVector%2520search%2520is%2520a%2520way%2Cbecoming%2520more%2520and%2520more%2520common" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://www.</span><span class="visible">algolia.com/blog/ai/wha</span><span class="invisible">t-is-vector-search/#:~:text=Vector%20search%20is%20a%20way,becoming%20more%20and%20more%20common</span><span class="ellipsis"></span></a>.</i></p><p data-pid="o7YXBAGD">[3] </p><p data-pid="6a8gnnCh">FAISS: <i><a class="external" href="https://link.zhihu.com/?target=https%3A//faiss.ai/" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">faiss.ai/</span><span class="invisible"></span></a></i></p><p data-pid="NHb-dkfn">[4] </p><p data-pid="xZadkiPr">Pinecone: <i><a class="external" href="https://link.zhihu.com/?target=https%3A//www.pinecone.io/" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://www.</span><span class="visible">pinecone.io/</span><span class="invisible"></span></a></i></p><p data-pid="KwKXT78T">[5] </p><p data-pid="XUnVCHo2">Weaviate: <i><a class="external" href="https://link.zhihu.com/?target=https%3A//weaviate.io/" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">weaviate.io/</span><span class="invisible"></span></a></i></p><p data-pid="z-KSo_11">[6] </p><p data-pid="b0oGhLu_">Kinetica: <i><a class="external" href="https://link.zhihu.com/?target=https%3A//www.kinetica.com/" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://www.</span><span class="visible">kinetica.com/</span><span class="invisible"></span></a></i></p><p data-pid="8w313FYe">[7] </p><p data-pid="JeP4kTU3">欧几里得距离: <i><a class="external" href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E6%25AC%25A7%25E5%2587%25A0%25E9%2587%258C%25E5%25BE%2597%25E8%25B7%259D%25E7%25A6%25BB" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">zh.wikipedia.org/wiki/%</span><span class="invisible">E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%B7%9D%E7%A6%BB</span><span class="ellipsis"></span></a></i></p><p data-pid="IGX2Wcza">[8] </p><p data-pid="wuEwuDq0">余弦相似度: <i><a class="external" href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/zh-sg/%25E4%25BD%2599%25E5%25BC%25A6%25E7%259B%25B8%25E4%25BC%25BC%25E6%2580%25A7" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">zh.wikipedia.org/zh-sg/</span><span class="invisible">%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E6%80%A7</span><span class="ellipsis"></span></a></i></p><p data-pid="zZwgMUUU">[9] </p><p data-pid="oS2QpJNl">点积: <i><a class="external" href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/zh-sg/%25E7%2582%25B9%25E7%25A7%25AF" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">zh.wikipedia.org/zh-sg/</span><span class="invisible">%E7%82%B9%E7%A7%AF</span><span class="ellipsis"></span></a></i></p><p data-pid="J-V6P4V5">[10] </p><p data-pid="C5z7qt59">inverted file index(IVF): <i><a class="external" href="https://link.zhihu.com/?target=https%3A//towardsdatascience.com/similarity-search-with-ivfpq-9c6348fd4db3" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">towardsdatascience.com/</span><span class="invisible">similarity-search-with-ivfpq-9c6348fd4db3</span><span class="ellipsis"></span></a></i></p><p data-pid="WtVPgTsq">[11] </p><p data-pid="CXq3r9S1">Product Quantization(PQ): <i><a class="external" href="https://link.zhihu.com/?target=https%3A//towardsdatascience.com/product-quantization-for-similarity-search-2f1f67c5fddd" rel="nofollow noreferrer" target="_blank"><span class="invisible">https://</span><span class="visible">towardsdatascience.com/</span><span class="invisible">product-quantization-for-similarity-search-2f1f67c5fddd</span><span class="ellipsis"></span></a></i></p></div><link href="../style.css" rel="stylesheet"/><div class="ContentItem-time" role="button" tabindex="0"><a href="https://zhuanlan.zhihu.com/p/627254037">发布于 2023-05-06 14:42</a><span>・IP 属地新加坡</span></div></div>